{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Analiza sentymentu z wykorzystaniem BERT i zbioru Amazon Reviews\n",
    "\n",
    "## Przygotowanie środowiska"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install -qq transformers\n",
    "!pip install wget\n",
    "!pip install --upgrade imbalanced-learn\n",
    "!pip install pyenchant\n",
    "!apt-get install -y libenchant-dev\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inicjalizacja stałych:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "BERT_URL = \"https://github.com/parvex/BERT-sentiment-analasysis/raw/BIG-BRANCH-WITH-BERT-USE-CAREFULLY/predict_review/model/model.pt\"\n",
    "BERT_path = os.path.join(\"model\", \"model.pt\")\n",
    "DATASET_URL = \"https://github.com/parvex/BERT-sentiment-analasysis/raw/BIG-BRANCH-WITH-BERT-USE-CAREFULLY/data/dataset.csv\"\n",
    "DATASET_PATH = os.path.join(\"data\", \"dataset.csv\")\n",
    "class_names = ['1', '2', '3', '4', '5']\n",
    "RANDOM_SEED = 1232\n",
    "TOKEN_MAX_LEN = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 2\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importowanie bibliotek:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import collections\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import wget\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, average_precision_score, recall_score, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import requests\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import torch.nn.functional as F\n",
    "from google.colab import drive\n",
    "from shutil import copyfile\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "import nltk as nltk\n",
    "from enchant.checker import SpellChecker\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "import spacy\n",
    "\n",
    "# Uncomment if you want to save the model on Google Drive after the training\n",
    "#drive.mount('/content/drive', force_remount=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "util.py:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def check_file_status(filepath, filesize):\n",
    "  sys.stdout.write('\\r')\n",
    "  sys.stdout.flush()\n",
    "  size = int(os.stat(filepath).st_size)\n",
    "  percent_complete = (size/filesize)*100\n",
    "  sys.stdout.write('%.3f %s' % (percent_complete, '% Completed'))\n",
    "  sys.stdout.flush()\n",
    "\n",
    "\n",
    "def download_file(file_url: str, target_path: str):\n",
    "  os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
    "  req = requests.get(file_url, stream=True)\n",
    "  filesize = int(req.headers['Content-length'])\n",
    "  with open(target_path, 'wb') as outfile:\n",
    "    chunk_size = 1048576\n",
    "    for chunk in req.iter_content(chunk_size=chunk_size):\n",
    "      outfile.write(chunk)\n",
    "      if chunk_size < filesize:\n",
    "        check_file_status(target_path, filesize)\n",
    "    check_file_status(target_path, filesize)\n",
    "    print()\n",
    "\n",
    "\n",
    "def download_bert():\n",
    "  print('Downloading BERT...')\n",
    "  download_file(BERT_URL, BERT_path)\n",
    "\n",
    "\n",
    "def download_dataset():\n",
    "  print('Downloading dataset...')\n",
    "  download_file(DATASET_URL, DATASET_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pobieranie zbioru danych i rozpakowywanie:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "if not os.path.exists(DATASET_PATH):\n",
    "  download_dataset()\n",
    "df = pd.read_csv(\"./data/dataset.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analiza danych:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "       reviewerID        asin            reviewerName   helpful  \\\n0   APYOBQE6M18AA  0615391206         Martin Schwartz    [0, 0]   \n1  A1JVQTAGHYOL7F  0615391206           Michelle Dinh    [0, 0]   \n2  A3UPYGJKZ0XTU4  0615391206            mirasreviews  [26, 27]   \n3  A2MHCTX43MIMDZ  0615391206  M. Johnson \"Tea Lover\"  [14, 18]   \n4   AHAI85T5C2DH3  0615391206                PugLover    [0, 0]   \n\n                                          reviewText  overall  \\\n0  My daughter wanted this book and the price on ...      5.0   \n1  I bought this zoku quick pop for my daughterr ...      5.0   \n2  There is no shortage of pop recipes available ...      4.0   \n3  This book is a must have if you get a Zoku (wh...      5.0   \n4  This cookbook is great.  I have really enjoyed...      4.0   \n\n                                             summary  unixReviewTime  \\\n0                                         Best Price      1382140800   \n1                                               zoku      1403049600   \n2  Excels at Sweet Dessert Pops, but Falls Short ...      1367712000   \n3                                    Creative Combos      1312416000   \n4            A must own if you own the Zoku maker...      1402099200   \n\n    reviewTime  \n0  10 19, 2013  \n1  06 18, 2014  \n2   05 5, 2013  \n3   08 4, 2011  \n4   06 7, 2014  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviewerID</th>\n      <th>asin</th>\n      <th>reviewerName</th>\n      <th>helpful</th>\n      <th>reviewText</th>\n      <th>overall</th>\n      <th>summary</th>\n      <th>unixReviewTime</th>\n      <th>reviewTime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>APYOBQE6M18AA</td>\n      <td>0615391206</td>\n      <td>Martin Schwartz</td>\n      <td>[0, 0]</td>\n      <td>My daughter wanted this book and the price on ...</td>\n      <td>5.0</td>\n      <td>Best Price</td>\n      <td>1382140800</td>\n      <td>10 19, 2013</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A1JVQTAGHYOL7F</td>\n      <td>0615391206</td>\n      <td>Michelle Dinh</td>\n      <td>[0, 0]</td>\n      <td>I bought this zoku quick pop for my daughterr ...</td>\n      <td>5.0</td>\n      <td>zoku</td>\n      <td>1403049600</td>\n      <td>06 18, 2014</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A3UPYGJKZ0XTU4</td>\n      <td>0615391206</td>\n      <td>mirasreviews</td>\n      <td>[26, 27]</td>\n      <td>There is no shortage of pop recipes available ...</td>\n      <td>4.0</td>\n      <td>Excels at Sweet Dessert Pops, but Falls Short ...</td>\n      <td>1367712000</td>\n      <td>05 5, 2013</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A2MHCTX43MIMDZ</td>\n      <td>0615391206</td>\n      <td>M. Johnson \"Tea Lover\"</td>\n      <td>[14, 18]</td>\n      <td>This book is a must have if you get a Zoku (wh...</td>\n      <td>5.0</td>\n      <td>Creative Combos</td>\n      <td>1312416000</td>\n      <td>08 4, 2011</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AHAI85T5C2DH3</td>\n      <td>0615391206</td>\n      <td>PugLover</td>\n      <td>[0, 0]</td>\n      <td>This cookbook is great.  I have really enjoyed...</td>\n      <td>4.0</td>\n      <td>A must own if you own the Zoku maker...</td>\n      <td>1402099200</td>\n      <td>06 7, 2014</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(551682, 9)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 551682 entries, 0 to 551681\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   reviewerID      551682 non-null  object \n",
      " 1   asin            551682 non-null  object \n",
      " 2   reviewerName    546729 non-null  object \n",
      " 3   helpful         551682 non-null  object \n",
      " 4   reviewText      551682 non-null  object \n",
      " 5   overall         551682 non-null  float64\n",
      " 6   summary         551682 non-null  object \n",
      " 7   unixReviewTime  551682 non-null  int64  \n",
      " 8   reviewTime      551682 non-null  object \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 42.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Histogram ilości słów w opinii:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 0, 'review score')"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='overall', data=df)\n",
    "plt.xlabel('review score')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<seaborn.axisgrid.FacetGrid at 0x21b843367f0>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 360x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numbers_of_words = df['reviewText'].str.split().str.len()\n",
    "plot = sns.displot(numbers_of_words, )\n",
    "plot.set_axis_labels('Length of review in words', 'Count')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jak widać zbiór jest mocno niezbalansowany, więc istnieje konieczność jego zbalansowania. Ze względu na tekstowy charakter zbioru zastosowanie generującego upsamplingu odpada, iilość danych w zbiorze jest duża, więc undersampling będzie odpowiednim rozwiązaniem.\n",
    "\n",
    "Przeważająca większość opinii jest krótsza niż 512 słów.\n",
    "\n",
    "### Definicja klasy ReviewDataset potrzebnej do przeprowadzenia treningu:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "\n",
    "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "    self.reviews = reviews\n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.reviews)\n",
    "\n",
    "  def __getitem__(self, item):\n",
    "    review = str(self.reviews[item])\n",
    "    target = self.targets[item]\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      review,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    return {\n",
    "      'review_text': review,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.long)\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definicja modelu SentimentClassifier:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "  def __init__(self, n_classes, pretrained_model_name):\n",
    "    super().__init__()\n",
    "    self.bert = BertModel.from_pretrained(pretrained_model_name)\n",
    "    self.drop = nn.Dropout(p=0.5)\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "      return_dict=False\n",
    "    )\n",
    "    output = self.drop(pooled_output)\n",
    "    return self.out(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definicja pomocniczych metod:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = ReviewDataset(\n",
    "    reviews=df.reviewText.to_numpy(),\n",
    "    targets=df.overall.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    "  )\n",
    "\n",
    "def train_epoch(\n",
    "        model,\n",
    "        data_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        n_examples\n",
    "):\n",
    "  model = model.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, losses\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "      loss = loss_fn(outputs, targets)\n",
    "\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "      losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "\n",
    "def get_predictions(model, data_loader, device):\n",
    "  model = model.eval()\n",
    "\n",
    "  review_texts = []\n",
    "  predictions = []\n",
    "  prediction_probs = []\n",
    "  real_values = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      texts = d[\"review_text\"]\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "      review_texts.extend(texts)\n",
    "      predictions.extend(preds)\n",
    "      prediction_probs.extend(probs)\n",
    "      real_values.extend(targets)\n",
    "\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "  real_values = torch.stack(real_values).cpu()\n",
    "  return review_texts, predictions, prediction_probs, real_values\n",
    "\n",
    "def show_confusion_matrix(confusion_matrix):\n",
    "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "  plt.ylabel('True sentiment')\n",
    "  plt.xlabel('Predicted sentiment')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Przygotowanie zbiorów treningowego i testowego:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BertTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-a7e1962fc11f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtokenizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mBertTokenizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mPRE_TRAINED_MODEL_NAME\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mdf_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdf_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.25\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mRANDOM_SEED\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstratify\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'overall'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mtrain_data_loader\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_data_loader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mTOKEN_MAX_LEN\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mBATCH_SIZE\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mtest_data_loader\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_data_loader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mTOKEN_MAX_LEN\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mBATCH_SIZE\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'BertTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "df['overall'] -= 1\n",
    "df_train, df_test = train_test_split(df, test_size=0.25, random_state=RANDOM_SEED, stratify=df[['overall']])\n",
    "print('df_train: ' + str(len(df_train)))\n",
    "print('df test: ' + str(len(df_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podział klas zbioru treningowego:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.countplot(x='overall',data=df_train)\n",
    "plt.xlabel('review score')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jak wynika z analizy, większość słów mieści się w zakresie 0-256 słów, więc ustalenie limitu tokenów BERT na górny próg - 256 będzie wystarczające. Dłuższe opinie zostaną skrócone do długości 256 tokenów."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Przygotowanie do treningu:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, TOKEN_MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, TOKEN_MAX_LEN, BATCH_SIZE)\n",
    "\n",
    "model = SentimentClassifier(len(class_names), PRE_TRAINED_MODEL_NAME)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "#class weights for loss function for imbalanced problem\n",
    "class_weights = compute_class_weight(classes=[0,1,2,3,4], y=df_train['overall'], class_weight='balanced')\n",
    "class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trening:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'defaultdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-df8e4948847c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mhistory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdefaultdict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mbest_accuracy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'defaultdict' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    len(df_train)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "  val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    test_data_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(df_test)\n",
    "  )\n",
    "\n",
    "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "  print()\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc\n",
    "\n",
    "# Uncomment to save model to Google Drive:\n",
    "# os.makedirs(\"model\", exist_ok=True)\n",
    "# torch.save(model.state_dict(), \"model/model.pt\")\n",
    "# os.makedirs('/content/drive/My Drive/BERT', exist_ok = True)\n",
    "# copyfile('model/model.pt', '/content/drive/My Drive/BERT/model.pt')\n",
    "# drive.flush_and_unmount()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wyniki treningu"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ewaluacja na zbiorze testowym:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 6.00 GiB total capacity; 4.32 GiB already allocated; 21.16 MiB free; 4.37 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-17-56ac0c96e1ed>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m test_acc, _ = eval_model(\n\u001B[0m\u001B[0;32m      2\u001B[0m   \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m   \u001B[0mtest_data_loader\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m   \u001B[0mloss_fn\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m   \u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Repo\\NLP\\training.py\u001B[0m in \u001B[0;36meval_model\u001B[1;34m(model, data_loader, loss_fn, device, n_examples)\u001B[0m\n\u001B[0;32m     56\u001B[0m       \u001B[0mtargets\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0md\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"targets\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 58\u001B[1;33m       outputs = model(\n\u001B[0m\u001B[0;32m     59\u001B[0m         \u001B[0minput_ids\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     60\u001B[0m         \u001B[0mattention_mask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mattention_mask\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ZZSN\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Repo\\NLP\\SentimentClassifier.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, attention_mask)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_ids\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mattention_mask\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m         _, pooled_output = self.bert(\n\u001B[0m\u001B[0;32m     18\u001B[0m             \u001B[0minput_ids\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m             \u001B[0mattention_mask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mattention_mask\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ZZSN\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ZZSN\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    962\u001B[0m         \u001B[0mhead_mask\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_head_mask\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhead_mask\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnum_hidden_layers\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    963\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 964\u001B[1;33m         embedding_output = self.embeddings(\n\u001B[0m\u001B[0;32m    965\u001B[0m             \u001B[0minput_ids\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    966\u001B[0m             \u001B[0mposition_ids\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mposition_ids\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ZZSN\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ZZSN\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001B[0m\n\u001B[0;32m    200\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0minputs_embeds\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    201\u001B[0m             \u001B[0minputs_embeds\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mword_embeddings\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 202\u001B[1;33m         \u001B[0mtoken_type_embeddings\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtoken_type_embeddings\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtoken_type_ids\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    203\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    204\u001B[0m         \u001B[0membeddings\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minputs_embeds\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mtoken_type_embeddings\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ZZSN\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ZZSN\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    155\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 156\u001B[1;33m         return F.embedding(\n\u001B[0m\u001B[0;32m    157\u001B[0m             \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpadding_idx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax_norm\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    158\u001B[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ZZSN\\lib\\site-packages\\torch\\nn\\functional.py\u001B[0m in \u001B[0;36membedding\u001B[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[0;32m   1914\u001B[0m         \u001B[1;31m# remove once script supports set_grad_enabled\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1915\u001B[0m         \u001B[0m_no_grad_embedding_renorm_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_norm\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnorm_type\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1916\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membedding\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpadding_idx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscale_grad_by_freq\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msparse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1917\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1918\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 6.00 GiB total capacity; 4.32 GiB already allocated; 21.16 MiB free; 4.37 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "test_acc, _ = eval_model(\n",
    "  model,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(df_test)\n",
    ")\n",
    "\n",
    "test_acc.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "  model,\n",
    "  test_data_loader,\n",
    "  device\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Macierz pomyłek oraz średni moduł błędu:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "show_confusion_matrix(df_cm)\n",
    "torch.mean(torch.abs(y_test - y_pred) * 1.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metryki:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test_vec = label_binarize(y_test, classes=[0,1,2,3,4])\n",
    "precision, recall, _ = precision_recall_curve(y_test_vec.ravel(), y_pred_probs.ravel())\n",
    "average_precision = average_precision_score(y_test_vec, y_pred_probs, average=\"micro\")\n",
    "average_recall = recall_score(y_test, y_pred, average=\"micro\")\n",
    "f1_score = 2*average_precision*average_recall/(average_precision+average_recall)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "plt.figure()\n",
    "plt.step(recall, precision, where='post')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\n",
    "  'Average precision, recall, area under curve, f1 score, micro-averaged over all classes: AP={0:0.2f}, AR={1:0.2f}, AUC={2:0.2f}, F1={3:0.2f}'\n",
    "    .format(average_precision, average_recall, pr_auc, f1_score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sprawdzenie pojedynczej opinii\n",
    "\n",
    "Musimy najpierw podać definicję klasy Preprocessing przeprowadzającej wstępne przetwarzanie opinii:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rep = {'\\n': ' ', '\\\\': ' ', '/': '', '-': ' ',\n",
    "       '\"': ' \" ', ',': ' , ', '.': ' . ', '!': ' ! ',\n",
    "       '?': ' ? ', \"n't\": \" not\", \"'ll\": \" will\", '*': ' * ',\n",
    "       '(': ' ( ', ')': ' ) ', \"s'\": \"s '\"}\n",
    "rep = dict((re.escape(k), v) for k, v in rep.items())\n",
    "pattern = re.compile(\"|\".join(rep.keys()))\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "class Preprocessing:\n",
    "\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    self.nlp = spacy.load(\"en\")\n",
    "\n",
    "  def preprocess_text(self, original_text: str):\n",
    "    if original_text == '':\n",
    "      return \"\"\n",
    "    original_text = \" \".join(str(original_text).split()[:TOKEN_MAX_LEN])\n",
    "    # remove http links and numbers\n",
    "    processed_text = re.sub(r'(https?://(www\\.)?[^\\s]+)|\\d+', \"\", original_text)\n",
    "    processed_text = pattern.sub(lambda m: rep[re.escape(m.group(0))], processed_text)\n",
    "    named_entities = Preprocessing.get_named_entities_list(processed_text)\n",
    "    for name in named_entities:\n",
    "      processed_text.replace(name, \"\")\n",
    "\n",
    "    incorrect_words, suggested_words = self.identify_incorrect_words(processed_text)\n",
    "    if len(incorrect_words) == 0:\n",
    "      processed_text = self._predict_words(processed_text, incorrect_words, suggested_words)\n",
    "\n",
    "    doc = self.nlp(processed_text)\n",
    "    text = \" \".join([token.lemma_.lower().strip() if token.lemma_ != \"-PRON-\" else token.lower_ for token in doc])\n",
    "    return text\n",
    "\n",
    "  def _predict_words(self, text, incorrect_words, spell_checker_suggestions):\n",
    "    for i, word in enumerate(incorrect_words):\n",
    "      if len(spell_checker_suggestions[i]) > 0:\n",
    "        text = text.replace(word, spell_checker_suggestions[i][0], 1)\n",
    "    return text\n",
    "\n",
    "  @staticmethod\n",
    "  def identify_incorrect_words(text):\n",
    "    ignorewords = [\"!\", \",\", \".\", \"\\\"\", \"?\", '(', ')', '*', '\\'']\n",
    "    spell_checker = SpellChecker(\"en_US\")\n",
    "    words = text.split()\n",
    "    # get incorrect words\n",
    "    incorrect_words = [w for w in words if not spell_checker.check(w) and w not in ignorewords]\n",
    "    suggested_words = [spell_checker.suggest(word) for word in incorrect_words]\n",
    "    return incorrect_words, suggested_words\n",
    "\n",
    "  @staticmethod\n",
    "  def get_named_entities_list(text: str):\n",
    "    chunked = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(text)))\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "    for i in chunked:\n",
    "      if type(i) == nltk.Tree:\n",
    "        current_chunk.append(\" \".join([token for token, pos in i.leaves()]))\n",
    "      if current_chunk:\n",
    "        named_entity = \" \".join(current_chunk)\n",
    "        if named_entity not in continuous_chunk:\n",
    "          continuous_chunk.append(named_entity)\n",
    "          current_chunk = []\n",
    "      else:\n",
    "        continue\n",
    "    return continuous_chunk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "review_text = \"\"\"I like it, perfect\"\"\"\n",
    "preprocessing = Preprocessing()\n",
    "preprocessed_text = preprocessing.preprocess_text(review_text)\n",
    "encoded_review = tokenizer.encode_plus(\n",
    "  preprocessed_text,\n",
    "  max_length=TOKEN_MAX_LEN,\n",
    "  add_special_tokens=True,\n",
    "  return_token_type_ids=False,\n",
    "  pad_to_max_length=True,\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',\n",
    "  verbose=False\n",
    ")\n",
    "input_ids = encoded_review['input_ids'].to(device)\n",
    "attention_mask = encoded_review['attention_mask'].to(device)\n",
    "\n",
    "output = model(input_ids, attention_mask)\n",
    "_, prediction = torch.max(output, dim=1)\n",
    "\n",
    "print(f'Review text: {review_text}')\n",
    "print(f'Processed review text: {preprocessed_text}')\n",
    "print(f'Sentiment  : {class_names[prediction]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dziękujemy :)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}